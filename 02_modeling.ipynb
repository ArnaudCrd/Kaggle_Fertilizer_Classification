{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üß™ Pr√©diction de fertilisants ‚Äì Kaggle Challenge\n",
    "**Auteur** : Arnaud Ch√©ridi\n",
    "üìÖ Date : Juin 2025\n",
    "üìç Comp√©tition : [Playground Series - Season 3, Episode 16](https://www.kaggle.com/competitions/playground-series-s3e16)\n",
    "üéØ Objectif : Pr√©dire les 3 fertilisants les plus probables √† partir de donn√©es agronomiques synth√©tiques.\n",
    "\n",
    "---"
   ],
   "id": "5c43c055c42abdaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Mod√©lisation\n",
    "\n",
    "Ce notebook contient les √©tapes de s√©lection de variables, d‚Äôentra√Ænement de plusieurs mod√®les de machine learning, ainsi que leur √©valuation selon la m√©trique de la comp√©tition."
   ],
   "id": "2ccd977c56e475ef"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T21:24:32.753630Z",
     "start_time": "2025-07-15T21:24:32.750599Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T21:22:43.233378Z",
     "start_time": "2025-07-15T21:22:42.999933Z"
    }
   },
   "cell_type": "code",
   "source": "train = pd.read_csv('data/train.csv')",
   "id": "a5bcef0ca1f50d49",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pr√©traitement des donn√©es",
   "id": "be6abd2f82a51582"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T21:24:56.854411Z",
     "start_time": "2025-07-15T21:24:56.775314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorical_features = ['Soil Type', 'Crop Type']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Fertilizer Encoded'] = label_encoder.fit_transform(train['Fertilizer Name'])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(), categorical_features),\n",
    "        ('num', StandardScaler(), ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ],
   "id": "adbf9ef3f962bd1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mise en place des grilles de recherche",
   "id": "bbc5f56c3c288582"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_grid = {\n",
    "    \"LogisticRegression\": (\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        {\"classifier__C\": [0.01, 0.1, 1, 10, 100], \"classifier__penalty\": ['l2'], \"classifier__solver\": ['lbfgs']}\n",
    "    ),\n",
    "    \"KNN\": (\n",
    "        KNeighborsClassifier(),\n",
    "        {\"classifier__n_neighbors\": [3, 5, 7, 9], \"classifier__weights\": ['uniform', 'distance']}\n",
    "    ),\n",
    "    \"DecisionTree\": (\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        {\"classifier__max_depth\": [None, 10, 20, 30], \"classifier__min_samples_split\": [2, 5, 10]}\n",
    "    ),\n",
    "    \"NaiveBayes\": (\n",
    "        GaussianNB(),\n",
    "        {}\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {\"classifier__n_estimators\": [100, 200, 300], \"classifier__max_depth\": [None, 10, 20], \"classifier__min_samples_split\": [2, 5]}\n",
    "    ),\n",
    "    \"GradientBoosting\": (\n",
    "        GradientBoostingClassifier(),\n",
    "        {\"classifier__n_estimators\": [100, 200], \"classifier__learning_rate\": [0.1, 0.05], \"classifier__max_depth\": [3, 5]}\n",
    "    ),\n",
    "    \"HistGradientBoosting\": (\n",
    "        HistGradientBoostingClassifier(),\n",
    "        {\"classifier__learning_rate\": [0.1, 0.05], \"classifier__max_iter\": [100, 200], \"classifier__max_depth\": [None, 10]}\n",
    "    ),\n",
    "    \"MLP\": (\n",
    "        MLPClassifier(max_iter=500),\n",
    "        {\"classifier__hidden_layer_sizes\": [(100,), (50, 50), (100, 50)], \"classifier__alpha\": [0.0001, 0.001, 0.01]}\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        {\"classifier__n_estimators\": [100, 200], \"classifier__learning_rate\": [0.1, 0.05], \"classifier__max_depth\": [3, 6]}\n",
    "    ),\n",
    "    \"LightGBM\": (\n",
    "        LGBMClassifier(),\n",
    "        {\"classifier__n_estimators\": [100, 200], \"classifier__learning_rate\": [0.1, 0.05], \"classifier__num_leaves\": [31, 50]}\n",
    "    ),\n",
    "    \"CatBoost\": (\n",
    "        CatBoostClassifier(verbose=0),\n",
    "        {\"classifier__iterations\": [100, 200], \"classifier__learning_rate\": [0.1, 0.05], \"classifier__depth\": [6, 10]}\n",
    "    )\n",
    "}\n",
    "\n",
    "X = train.drop(columns=['Fertilizer Name', 'Fertilizer Encoded', 'id'])\n",
    "y = train['Fertilizer Encoded']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "results_summary = {}\n",
    "\n",
    "for name, (model, params) in model_grid.items():\n",
    "    print(f\"\\nTesting {name}...\")\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    grid = GridSearchCV(pipeline, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_val)\n",
    "    print(f\"Best params: {grid.best_params_}\")\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    results_summary[name] = {\n",
    "        \"model\": grid.best_estimator_,\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"accuracy\": acc\n",
    "    }\n",
    "\n",
    "    print(classification_report(y_val, y_pred, target_names=label_encoder.classes_))"
   ],
   "id": "90c433096be0557a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('results_summary.pkl', 'wb') as file:\n",
    "    pickle.dump(results_summary, file)"
   ],
   "id": "bb8a3ddaae9fa96f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('label_y.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)"
   ],
   "id": "a28bb6cd1100992c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T21:24:41.590242Z",
     "start_time": "2025-07-15T21:24:40.054079Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "with open('results_summary.pkl', 'rb') as file:\n",
    "    results_summary = pickle.load(file)\n",
    "\n",
    "with open('label_y.pkl', 'rb') as file:\n",
    "    label_encoder = pickle.load(file)"
   ],
   "id": "ecf6e61ac82c8c54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrainement d'un mod√®le de stacking avec les quatres meilleures mod√®les",
   "id": "e3efeb4b1a861ef8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T21:24:47.109927Z",
     "start_time": "2025-07-15T21:24:47.108088Z"
    }
   },
   "cell_type": "code",
   "source": "top_4 = sorted(results_summary.items(), key=lambda x: x[1][\"accuracy\"], reverse=True)[:4]",
   "id": "5f87be0b606d05b3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T21:25:00.392003Z",
     "start_time": "2025-07-15T21:25:00.211548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = train.drop(columns=['Fertilizer Name', 'Fertilizer Encoded', 'id'])\n",
    "y = train['Fertilizer Encoded']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "id": "1cd5769267b2c22a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-07-16T06:14:09.754442Z",
     "start_time": "2025-07-15T21:25:03.049821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estimators = [(name.lower(), model_info[\"model\"].named_steps[\"classifier\"]) for name, model_info in top_4]\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=XGBClassifier(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "param_grid = {\n",
    "    'classifier__final_estimator__learning_rate': [0.1, 0.05],\n",
    "    'classifier__final_estimator__n_estimators': [100, 200],\n",
    "    'classifier__final_estimator__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', stacking)\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X, y)"
   ],
   "id": "efaaf49c5df12c3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897533\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884875\n",
      "[LightGBM] [Info] Start training from score -1.880053\n",
      "[LightGBM] [Info] [LightGBM] [Info] Start training from score -1.897533\n",
      "Start training from score -1.884875\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] [LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671Start training from score -1.880053\n",
      "\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Start training from score -1.897533\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897533\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880053\n",
      "[LightGBM] [Info] Start training from score -1.897547\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909112\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094856\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884875\n",
      "[LightGBM] [Info] Start training from score -1.880053\n",
      "[LightGBM] [Info] Start training from score -1.897533\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880053\n",
      "[LightGBM] [Info] Start training from score -1.897547\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909112\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:25:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[23:25:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[23:25:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880053\n",
      "[LightGBM] [Info] Start training from score -1.897547\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909112\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094856\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:25:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[23:25:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897533\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884875\n",
      "[LightGBM] [Info] Start training from score -1.880053\n",
      "[LightGBM] [Info] Start training from score -1.897533\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:25:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[23:25:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 500000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897533\n",
      "[LightGBM] [Info] Start training from score -1.911544\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:25:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[23:25:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[23:25:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[23:25:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897520\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:59:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:59:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897520\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:59:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:00:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:00:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:00:05] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:00:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:00:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897520\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:00:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:00:28] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897520\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:00:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:04:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:04:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:04:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[00:04:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:04:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:04:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:04:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:04:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897553\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:04:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[00:04:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897520\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897520\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897520\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880066\n",
      "[LightGBM] [Info] Start training from score -1.897520\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884879\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911540\n",
      "[LightGBM] [Info] Start training from score -1.909125\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094839\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.170040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 202\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.884862\n",
      "[LightGBM] [Info] Start training from score -1.880050\n",
      "[LightGBM] [Info] Start training from score -1.897537\n",
      "[LightGBM] [Info] Start training from score -1.911557\n",
      "[LightGBM] [Info] Start training from score -1.909108\n",
      "[LightGBM] [Info] Start training from score -2.067671\n",
      "[LightGBM] [Info] Start training from score -2.094860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Data_Science/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[00:07:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:34] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:07:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:21] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:32] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:09:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:16] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:21] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[00:11:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1742444258230/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "edc082bc109eff5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
